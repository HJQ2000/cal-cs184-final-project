<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>  
    div.padded {  
      padding-top: 0px;  
      padding-right: 100px;  
      padding-bottom: 0.25in;  
      padding-left: 100px;  
    }  
  </style> 
<title>CS 184 Final Project</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>
<br />
<h1 align="middle">Final Project: Texture support in ray tracer</h1>
<h4 align="middle">Charlotte Mei</h4>
<h4 align="middle">Jingqi Huang</h4>
<h4 align="middle">Ryan Solan</h4>
<h4 align="middle">Yuankai Yang</h4>

<div class="padded">
    <h2 align="middle">Brief summarize</h2>
    <p>In project 3, we implemented a physically-based renderer that could render various objects based on ray tracing. 
        We were fascinated by the output images that the pathtracer produces, and decided to further improve its performance. 
        We noticed that the renderer doesn’t have texture support. Luckily, we learned about the basic algorithm of texture rendering in class. 
        Therefore, we reached at this final project topic - rendering with texture support.         
        We studied the codebase for project 3 and tried to add a texture model into the codebase. 
        We find this difficult to start with, so we learn to write a simplified version of ray tracer process with far less options. 
        We collected learning materials to do texture mapping for regular shape objects such as sphere and cube. 
        By now, we just have spheres in different colors.</p>
    
    <h2 align="middle">Technical Approach</h2>
    <div align="left">
        <p>These are some of the final images that we were able to produce by our modified path tracer. 
            On the upper left corner is the image texture we gave to the spheres inside the box.</p>
            <img src="images/brick.jpg" width="480px" />
            <img src="images/wave.jpg" width="480px" />
        <br>
        <p>Our basic idea is that when light intersects with object which we want to render with texture, the algorithm will return the corresponding values of the texture at that point of intersection instead of the original color.
            For sphere, we only need to find a continuous function that maps 3-dimensional coordinates to 2-dimensional texture uv-coordinates. Specifically, for every intersection, we map the 3d (x,y,z) position of the sphere to 2d uv coordinate of the texture and return the corresponding texture value at that uv coordinate. </p>
            <img src="images/code.jpg" width="480px" align="middle"/>
            <figcaption>the algorithm to convert uv coordinates</figcaption>
            At the very first, we implemented a checker-like texture by setting the texture color to white when the value of u+v is odd, while keeping the original color when u+v is a even number. e of u+v is odd, while keeping the original color when u+v is a even number. 
            </p>
    <h4 align="middle">Checker-like texture</h2>
    <div align="center">
        <table style="width=100%">
            <tr>
                <td>
                    <img src="images/1.png" width="480px" />
                </td>
                <td>
                    <img src="images/2.png" width="480px" />
                </td>
            </tr>
            <tr>
                <td>
                    <img src="images/3.png" width="480px" />
                </td>
                <td>
                    <img src="images/4.png" width="480px" />
                </td>
            </tr>
        </table>
    </div>

    <p>In our final results, we built a hard-coded scene, in which we have a very very big sphere in the bottom whose center is very far away so that it looks like a plane when we place our camera on top of it. We use this same idea to create the other walls of the scene. Between the “plane” spheres, we placed several small spheres and we have our light source on the top. To render the image in the slide,
         we mapped a earth texture image to the small sphere inside and changed all surrounding material types to mirror.</p>
         <img src="images/final.jpg" width="480px" align="middle"/>

    <p>Link to video introduction: https://drive.google.com/file/d/1XD1nSMe9jZD28l4in3Hp7XE0GUGIJufi/view?usp=sharing</p>
        
    <h2 align="middle">Resources</h2>
    <p>http://www.cs.toronto.edu/~kyros/courses/418/Lectures/lecture.2010f.07.pdf</p>
    <p>http://graphics.ucsd.edu/~henrik/papers/practical_microcylinder_appearance_model_for_cloth_rendering.pdf</p>
    
    <h2 align="middle">Contributions from each team member</h2>
    <p>Jingqi Huang, Charlotte Mei and Ryan Solan all contributed to the base algorithm of the renderer, 
        Apart from that, Jingqi worked to produce the checker-like texture;
        Ryan modified the renderer to produce the final images;
        Charlotte made the slides and websites for the milestones and presentation.</p>

</div>
</body>
</html>




